
import os
import torch
import json
import hashlib


def save_embedding_cache(cache_path: str, embedding_dict: dict):
    torch.save(embedding_dict, cache_path)


def load_embedding_cache(cache_path: str):
    return torch.load(cache_path) if os.path.exists(cache_path) else {}


def get_cache_path(prefix: str, dataset_name: str, split: str, cache_dir="embeddings_cache"):
    os.makedirs(cache_dir, exist_ok=True)
    file_name = f"{prefix}_{dataset_name}_{split}.pt"
    return os.path.join(cache_dir, file_name)


def get_result_path(dataset_name: str, split: str, out_dir="results"):
    os.makedirs(out_dir, exist_ok=True)
    return os.path.join(out_dir, f"{dataset_name}_{split}_eval.csv")


def get_json_result_path(dataset_name: str, split: str, out_dir="results"):
    os.makedirs(out_dir, exist_ok=True)
    return os.path.join(out_dir, f"{dataset_name}_{split}_raw_results.json")


def compute_md5(obj):
    if isinstance(obj, (dict, list)):
        obj = json.dumps(obj, sort_keys=True)
    return hashlib.md5(obj.encode("utf-8")).hexdigest()[:8]


def filter_unfinished_queries(result_json_path: str, all_ids: list):
    """用于断点续评估：根据已经存在的 JSON 跳过评过的 query_id"""
    if not os.path.exists(result_json_path):
        return set(all_ids)
    with open(result_json_path, "r", encoding="utf-8") as f:
        completed = json.load(f)
    finished_ids = set(entry["query_id"] for entry in completed)
    return [qid for qid in all_ids if qid not in finished_ids]
